{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_1_Pre_Made_Estimators.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sthalles/tensorflow-tutorials/blob/master/Day_1_Pre_Made_Estimators_Solutions.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "cqTmrQ_S2uHN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pre-Made Estimators"
      ]
    },
    {
      "metadata": {
        "id": "Rs-U0Gbg2tOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e30ae96d-7935-4cf6-c4cd-d95d42f92fef"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09FZfGX73c10",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Estimator is a high-level Tensorflow API. \n",
        "- It is built on top of the TensorFlow core API.\n",
        "\n",
        "It follows a **train-evaluate-predict** loop.\n",
        "\n",
        "It is made to handle the boring steps of training an ML model like:\n",
        "\n",
        "- Creating the computational graph\n",
        "- Initializing Variables\n",
        "- Training, testing, and making predictions\n",
        "- Visualizing training specific variables (learning rate, trainable variables and performance measures)\n",
        "- Saving the model\n",
        "\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/tensorflow_programming_environment.png)\n",
        "\n",
        "To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n",
        "\n",
        "1.  Create one or more **input functions**.\n",
        "2.  Define the model's **feature columns**.\n",
        "3. Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
        "4. Train and Evaluate\n",
        "\n",
        "# Loading Data"
      ]
    },
    {
      "metadata": {
        "id": "zyFPmARd8fUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "dcfd863c-fce8-4bdd-db21-7d8d3bfda2e0"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"DO NOT NEED CHANGES\"\"\"\n",
        "def maybe_download():\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GmASDzpA3zBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0573a57a-7267-41c1-994f-4e77a9919c9d"
      },
      "cell_type": "code",
      "source": [
        "\"\"\"DO NOT NEED CHANGES\"\"\"\n",
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "  train_path, test_path = maybe_download()\n",
        "  train_data = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  test_data = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  \n",
        "  train_input = train_data[CSV_COLUMN_NAMES[0:-1]]\n",
        "  train_labels = train_data[CSV_COLUMN_NAMES[-1]]\n",
        "  \n",
        "  test_input = test_data[CSV_COLUMN_NAMES[0:-1]]\n",
        "  test_labels = test_data[CSV_COLUMN_NAMES[-1]]\n",
        "  \n",
        "  return (train_input, train_labels), (test_input, test_labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Emtq_oW0HtbZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "![alt text](https://www.tensorflow.org/images/iris_three_species.jpg)"
      ]
    },
    {
      "metadata": {
        "id": "_HNxFcVM8fyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "574b317a-481e-40e6-c32e-a4c834bf0a46"
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_dataset()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L4dHRFlWUgDU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "506f8356-f3a2-4ced-d994-30e0250b10fe"
      },
      "cell_type": "code",
      "source": [
        "print(\"Visualize the Dataset shapes\")\n",
        "print(\"Train input:\", X_train.shape)\n",
        "print(\"Train labels:\", y_train.shape)\n",
        "print(\"Test input:\", X_test.shape)\n",
        "print(\"Test labels:\", y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Visualize the Dataset shapes\n",
            "Train input: (120, 4)\n",
            "Train labels: (120,)\n",
            "Test input: (30, 4)\n",
            "Test labels: (30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3nUjVLf_H1nh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Iris data set contains 4 features and 1 label. \n",
        "\n",
        "The 4 **features** identify the following botanical characteristics of individual Iris flowers:\n",
        "\n",
        "- sepal length\n",
        "- sepal width\n",
        "- petal length\n",
        "- petal width\n",
        "\n",
        "![alt text](http://s5047.pcdn.co/wp-content/uploads/2015/04/iris_petal_sepal.png)\n",
        "\n",
        "Our model will represent these features as float32 numerical data.\n",
        "\n",
        "The **label** identifies the Iris species, which must be one of the following:\n",
        "\n",
        "- Iris setosa (0)\n",
        "- Iris versicolor (1)\n",
        "- Iris virginica (2)\n",
        "\n",
        "Our model will represent the label as int32 categorical data."
      ]
    },
    {
      "metadata": {
        "id": "t3GLxIFMHU0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "7cffb186-2617-490d-b36d-ef4d26ec267a"
      },
      "cell_type": "code",
      "source": [
        "X_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SepalLength</th>\n",
              "      <th>SepalWidth</th>\n",
              "      <th>PetalLength</th>\n",
              "      <th>PetalWidth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.4</td>\n",
              "      <td>2.8</td>\n",
              "      <td>5.6</td>\n",
              "      <td>2.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.9</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.7</td>\n",
              "      <td>3.8</td>\n",
              "      <td>1.7</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
              "0          6.4         2.8          5.6         2.2\n",
              "1          5.0         2.3          3.3         1.0\n",
              "2          4.9         2.5          4.5         1.7\n",
              "3          4.9         3.1          1.5         0.1\n",
              "4          5.7         3.8          1.7         0.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "G8Iuj0njHaNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "5c223696-95f5-47a3-c71f-4a6de454ac8d"
      },
      "cell_type": "code",
      "source": [
        "y_train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2\n",
              "1    1\n",
              "2    2\n",
              "3    0\n",
              "4    0\n",
              "Name: Species, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "IFad94RrSCyZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##  Exercise: Creating Validation (Dev set)\n",
        "\n",
        "The Iris dataset is divided into Training and Testing sets.\n",
        "\n",
        "This time, let's **NOT** use the Test set for development. \n",
        "\n",
        "The idea is to have a different set for which we can perform **hyperparameter tuning** during training.\n",
        "\n",
        "That is the Dev or **Validation set**.\n",
        "\n",
        "- Separate the training set into 2 sets: **training** and **validation**.\n",
        "\n",
        "### Tip\n",
        "- *The size of the validation set may vary. 10 - 20% are good choices for this dataset.*\n",
        "- Use sklearn [train_test_split()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html).\n"
      ]
    },
    {
      "metadata": {
        "id": "PzlFnFP7SBcL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "24c624eb-94bc-4771-b03c-092e9d056c47"
      },
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OYQDKxHFVAyY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "04e2842a-ef12-44c5-c345-35ac94f00ed9"
      },
      "cell_type": "code",
      "source": [
        "print(\"Training/validation shapes\")\n",
        "print(\"Train input:\", X_train.shape)\n",
        "print(\"Train labels:\", y_train.shape)\n",
        "print(\"Test input:\", X_val.shape)\n",
        "print(\"Test labels:\", y_val.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training/validation shapes\n",
            "Train input: (102, 4)\n",
            "Train labels: (102,)\n",
            "Test input: (18, 4)\n",
            "Test labels: (18,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XE0JRtOAJ1Qi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating Input funcions\n",
        "\n",
        "**Input functions are responsible for feeding data to ML Models created with the TF Estimators API.**\n",
        "\n",
        "The Estimator expects an *input_function()* to return a [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) or a tuple of *(features, labels)*.\n",
        "\n",
        "Let's use the **tf.data.Dataset** as our input streaming.\n",
        "-  [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) is the recommended Tensorflow input pipeline.\n",
        "\n",
        "Hint: [tf.data.Dataset template](https://www.tensorflow.org/get_started/datasets_quickstart)"
      ]
    },
    {
      "metadata": {
        "id": "g69sCY5S8zYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "500cc96b-1b6a-47d5-ab34-0d545ebe3e50"
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(features, labels, batch_size):\n",
        "  \"\"\"\n",
        "  Provides input data for training\n",
        "  Return: A 'tf.data.Dataset' object: tuple (features, labels). \n",
        "          Or tuple (features, labels)\n",
        "  \"\"\"\n",
        "  \n",
        "  # Create the dataset object and return it\n",
        "  # Make sure you shuffle and define the batch size as given by the 'batch_size' parameter\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "  dataset = dataset.shuffle(buffer_size=100)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset # return the dataset object"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3aWlJkPaGrXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "7672e7cb-556d-489b-8283-b25c5fbc53e3"
      },
      "cell_type": "code",
      "source": [
        "def eval_input_fn(features, labels, batch_size):\n",
        "  \n",
        "  features = dict(features)\n",
        "  if labels is None:\n",
        "    inputs = features\n",
        "  else:\n",
        "    inputs = (dict(features), labels)\n",
        "  \n",
        "  # Create the tf.data.Dataset() object and return it\n",
        "  # Set the number of epochs to 0\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "  dataset = dataset.repeat(1)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pf6z_QJxEFFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining the Feature Columns\n",
        "\n",
        "Now, we have to convert our data into **Tensors** so that our Model can use it.\n",
        "\n",
        "Feature Columns provides a representation of how our model should interpret the data it will receive.\n",
        "- Is this column Numerical, Categorical or what?\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/feature_columns/some_constructors.jpg)\n",
        "\n",
        "**Feature Columns** define the **type of features** we are going to feed into our Models.\n",
        "\n",
        "The choice of Feature Column depends on the Variable and Model type.\n",
        "\n",
        "Since the 4 feature columns of the Iris dataset are represented as continuos values, we need to especify it when creating the feature columns.\n",
        "\n",
        "To do that, we use the: [tf.feature_column.numeric_column()](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column) constructor.\n",
        "\n",
        "  - **tf.feature_column.numeric_column()** Represents real valued or numerical features.\n",
        "  \n",
        "Info++: [Feature Engineering](https://www.tensorflow.org/get_started/feature_columns)\n",
        "  \n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "PJEWtWQ_-v9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "8d04aa70-cf77-4a47-c3c3-780baefdbbc1"
      },
      "cell_type": "code",
      "source": [
        "# feature columns define how to use the feature data\n",
        "my_feature_columns = []\n",
        "for feature_column in X_train.keys():\n",
        "  # use tf.feature_column.numeric_column() to create a feature column and add it to the 'my_feature_columns' list\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=feature_column))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iihk9U-ubQbr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "1. Tune the hyperparameters bellow."
      ]
    },
    {
      "metadata": {
        "id": "QRwjJ4qbbbzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "3aefc97b-7030-4790-b71f-b26e398bb92c"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "number_of_classes = 3 # number of classes from the Iris dataset\n",
        "batch_size = 16 # number of examples to feed to the network per step\n",
        "max_step = 2000 # maximum number of training steps\n",
        "regularization = 0.001 # regularization strength\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCQTOJnbCjFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the Estimator\n",
        "\n",
        "An Estimator encapsulates all the necessary parts of a model. \n",
        "\n",
        "Some of the available Estimators include:\n",
        "\n",
        "1. **BoostedTrees** Classifier/Regressor\n",
        "2. **DNN Classifier**/Regressor\n",
        "3. **DNNLinearCombined** Classifier/Regressor\n",
        "4. **Linear** Classifier/Regressor\n",
        "\n",
        "Checkout: [tf.estimator](https://www.tensorflow.org/api_docs/python/tf/estimator)\n",
        "\n",
        "## Exercise\n",
        "\n",
        "1. Use the [tf.estimator.LinearClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier) to classify the Iris Dataset.\n",
        "\n",
        "Things to keep in mind.\n",
        "  - Linear models are very simple, for this case, pay special attention to the **number of classes** and the **learning rate** tunning.\n",
        "  - Play with different configurations of **batch size**, it can have dramatic effects on how quick the model converges."
      ]
    },
    {
      "metadata": {
        "id": "jQBtZvi8CHKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "590ebf27-7530-4bce-c073-48cc9dd98082"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(    \n",
        "    feature_columns=my_feature_columns, # pass the feature columns to the Linear Classifier\n",
        "    n_classes=number_of_classes, # Set the number of classes defined above\n",
        "    optimizer=tf.train.FtrlOptimizer( # Configure the loss function\n",
        "      learning_rate=learning_rate, # setup the learning rate\n",
        "      l1_regularization_strength=regularization # set the regularization strength \n",
        "    ))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp3k69rpbn\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp3k69rpbn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fdeaf055b70>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "aGnEdrbmoBGa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tip\n",
        "\n",
        "You do NOT need to define nor control the TensorFlow Session. \n",
        "*Estimators take care of that for you.*\n",
        "\n",
        "## Exercise\n",
        "\n",
        "Use the *classifier.train()* method to train the built classifier.\n",
        "- Pass the  *train_input_fn()* as a lambda so you can control its input parameters.\n",
        "- Set the *steps* parameter to the maximum number of steps you want to train your model."
      ]
    },
    {
      "metadata": {
        "id": "L4U3QtsFDHpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 908
        },
        "outputId": "874caae8-0b3f-48c8-ec9b-ddf3ab8d1ef6"
      },
      "cell_type": "code",
      "source": [
        "classifier.train(input_fn=lambda: train_input_fn(X_train, y_train, batch_size=batch_size), \n",
        "                 steps=max_step #  Number of steps for which to train model.\n",
        "                )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp3k69rpbn/model.ckpt.\n",
            "INFO:tensorflow:loss = 17.577797, step = 0\n",
            "INFO:tensorflow:global_step/sec: 244.599\n",
            "INFO:tensorflow:loss = 8.288761, step = 100 (0.414 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.833\n",
            "INFO:tensorflow:loss = 4.807881, step = 200 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 217.644\n",
            "INFO:tensorflow:loss = 5.272978, step = 300 (0.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 212.425\n",
            "INFO:tensorflow:loss = 6.930149, step = 400 (0.472 sec)\n",
            "INFO:tensorflow:global_step/sec: 215.467\n",
            "INFO:tensorflow:loss = 3.7425652, step = 500 (0.460 sec)\n",
            "INFO:tensorflow:global_step/sec: 222.168\n",
            "INFO:tensorflow:loss = 3.7090392, step = 600 (0.454 sec)\n",
            "INFO:tensorflow:global_step/sec: 225.272\n",
            "INFO:tensorflow:loss = 3.8810961, step = 700 (0.445 sec)\n",
            "INFO:tensorflow:global_step/sec: 212.993\n",
            "INFO:tensorflow:loss = 5.1052675, step = 800 (0.463 sec)\n",
            "INFO:tensorflow:global_step/sec: 218.175\n",
            "INFO:tensorflow:loss = 3.4128244, step = 900 (0.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 211.644\n",
            "INFO:tensorflow:loss = 4.452698, step = 1000 (0.468 sec)\n",
            "INFO:tensorflow:global_step/sec: 215.827\n",
            "INFO:tensorflow:loss = 3.254537, step = 1100 (0.466 sec)\n",
            "INFO:tensorflow:global_step/sec: 210.94\n",
            "INFO:tensorflow:loss = 2.7563725, step = 1200 (0.475 sec)\n",
            "INFO:tensorflow:global_step/sec: 212.009\n",
            "INFO:tensorflow:loss = 2.9894118, step = 1300 (0.468 sec)\n",
            "INFO:tensorflow:global_step/sec: 230.443\n",
            "INFO:tensorflow:loss = 2.4357004, step = 1400 (0.434 sec)\n",
            "INFO:tensorflow:global_step/sec: 207.58\n",
            "INFO:tensorflow:loss = 3.7694747, step = 1500 (0.485 sec)\n",
            "INFO:tensorflow:global_step/sec: 224.325\n",
            "INFO:tensorflow:loss = 3.632686, step = 1600 (0.441 sec)\n",
            "INFO:tensorflow:global_step/sec: 215.524\n",
            "INFO:tensorflow:loss = 1.8843393, step = 1700 (0.464 sec)\n",
            "INFO:tensorflow:global_step/sec: 221.806\n",
            "INFO:tensorflow:loss = 2.7223048, step = 1800 (0.451 sec)\n",
            "INFO:tensorflow:global_step/sec: 216.938\n",
            "INFO:tensorflow:loss = 2.5559866, step = 1900 (0.460 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/tmp3k69rpbn/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 3.299758.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7fdeaf055828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "hA3DUaUIDtFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "ee421621-e44d-45c0-9ea6-9aa065812c0f"
      },
      "cell_type": "code",
      "source": [
        "eval_results = classifier.evaluate(input_fn=lambda: eval_input_fn(X_test, y_test, batch_size=512))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-06-25-14:07:09\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp3k69rpbn/model.ckpt-2000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-06-25-14:07:09\n",
            "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.93333334, average_loss = 0.20646352, global_step = 2000, loss = 6.1939054\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: /tmp/tmp3k69rpbn/model.ckpt-2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u9mZmUjZRPTf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "863e2145-503b-4286-b807-1e301378e831"
      },
      "cell_type": "code",
      "source": [
        "eval_results['probabilities']"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-c24d57466394>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'probabilities'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'probabilities'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AuxmT16LtogI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Networks\n",
        "\n",
        "### Definition:\n",
        "\n",
        "\"*...a computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs.*\"\n",
        "\n",
        "- Function approximator\n",
        "- Very powerful for non-linear relationships\n",
        "- Represents a function as the composition of many functions.\n",
        "\n",
        "## Exercise\n",
        "\n",
        "1. Change the Linear Model Estimator to a Deep Neural Network.\n",
        "- Head over to the Tensorflow documentation for [tf.estimator.DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) and check it out.\n",
        "\n",
        "Think about:\n",
        "\n",
        "- How many layers you need\n",
        "- The number of units in each layer\n",
        "- The activation function used by default\n",
        "- The Gradient Descent Optimizer. \n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/custom_estimators/full_network.png)\n",
        "\n",
        "## Architecturing your network\n",
        "\n",
        "![LeNet-5](http://cs231n.github.io/assets/nn1/layer_sizes.jpeg)\n",
        "\n",
        "Neural Nets with more hidden layers are able to represent more complex functions. \n",
        "\n",
        "- With more power comes complicated decision boundaries.\n",
        "\n",
        "Take care with **Overfitting**!\n",
        "\n",
        "- It occurs when a model with **high capacity** fits the noise in the data instead of the (assumed) underlying relationship.\n"
      ]
    },
    {
      "metadata": {
        "id": "07xM_Mh0dlc8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regularization\n",
        "\n",
        "Effects of Regularization. The figure below shows the decision boundaries of the same DNN (20 hidden units), with different regularization penalties. \n",
        "\n",
        "Note that more regularization smooths the decision boundary.\n",
        "\n",
        "- It fights **Overfitting**.\n",
        "\n",
        "![alt text](http://cs231n.github.io/assets/nn1/reg_strengths.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "6C6iw34VuR2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}