{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_1_Pre_Made_Estimators.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sthalles/tensorflow-tutorials/blob/master/Day_1_Pre_Made_Estimators.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "cqTmrQ_S2uHN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pre-Made Estimators"
      ]
    },
    {
      "metadata": {
        "id": "Rs-U0Gbg2tOT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09FZfGX73c10",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Estimator is a high-level Tensorflow API. \n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/tensorflow_programming_environment.png)\n",
        "\n",
        "It provides functionalities for representing a complete model.\n",
        "1. Building the actual model\n",
        "2. Initialization\n",
        "3. Logging\n",
        "3. Saving and restoring\n",
        "2. Measuring\n",
        "3. Testing\n",
        "\n",
        "To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n",
        "\n",
        "1.  Create one or more input functions.\n",
        "2.  Define the model's feature columns.\n",
        "3. Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
        "4. Train and Evaluate\n",
        "\n",
        "## Loading data"
      ]
    },
    {
      "metadata": {
        "id": "zyFPmARd8fUg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def maybe_download():\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GmASDzpA3zBn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "  train_path, test_path = maybe_download()\n",
        "  train_data = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  test_data = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  \n",
        "  train_input = train_data[CSV_COLUMN_NAMES[0:-1]]\n",
        "  train_labels = train_data[CSV_COLUMN_NAMES[-1]]\n",
        "  \n",
        "  test_input = test_data[CSV_COLUMN_NAMES[0:-1]]\n",
        "  test_labels = test_data[CSV_COLUMN_NAMES[-1]]\n",
        "  \n",
        "  return (train_input, train_labels), (test_input, test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HNxFcVM8fyz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XE0JRtOAJ1Qi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating Input funcions"
      ]
    },
    {
      "metadata": {
        "id": "g69sCY5S8zYk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(features, labels, batch_size):\n",
        "  \"\"\"\n",
        "  A function that provides input data for training as minibatches\n",
        "  Return: A 'tf.data.Dataset' object: tuple (features, labels). \n",
        "          Or tuple (features, labels)\n",
        "  \"\"\"\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "  dataset = dataset.shuffle(buffer_size=100)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3aWlJkPaGrXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def eval_input_fn(features, labels, batch_size):\n",
        "  \n",
        "  features = dict(features)\n",
        "  if labels is None:\n",
        "    inputs = features\n",
        "  else:\n",
        "    inputs = (dict(features), labels)\n",
        "  \n",
        "  dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "  dataset = dataset.repeat(1)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pf6z_QJxEFFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Defining the Feature Columns\n",
        "\n",
        "Now, we have to convert our data into **Tensors** so that our Model can use it.\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/feature_columns/some_constructors.jpg)\n",
        "\n",
        "**Feature Columns** define the **type of features** we are going to feed into our Models.\n",
        "\n",
        "Since the 4 feature columns of the Iris dataset are represented as continuos values, we need to especify it when creating the feature columns.\n",
        "\n",
        "To do that, we use the: [tf.feature_column.numeric_column()](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column) constructor.\n",
        "\n",
        "  - **tf.feature_column.numeric_column()** Represents real valued or numerical features.\n",
        "  \n",
        "Checkout: [Feature Engineering](https://www.tensorflow.org/get_started/feature_columns)\n",
        "  \n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "PJEWtWQ_-v9s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# feature columns define how to use the feature data\n",
        "my_feature_columns = []\n",
        "for feature_column in X_train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=feature_column,\n",
        "                                                            default_value=None, # Default values to result missing values\n",
        "                                                            normalizer=None # Function to normalize data (after default value) \n",
        "                                                            ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCQTOJnbCjFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Building the Estimator\n",
        "\n",
        "An Estimator encapsulates all the necessary parts of a model. \n",
        "\n",
        "Some of the available Estimators include:\n",
        "\n",
        "1. **BoostedTrees** Classifier/Regressor\n",
        "2. **DNN Classifier**/Regressor\n",
        "3. **DNNLinearCombined** Classifier/Regressor\n",
        "4. **Linear** Classifier/Regressor\n",
        "\n",
        "Checkout: [tf.estimator](https://www.tensorflow.org/api_docs/python/tf/estimator)\n",
        "\n",
        "Your turn: Use the **tf.estimator.LinearClassifier** to classify the Iris Dataset.\n",
        "\n",
        "Things to keep in mind.\n",
        "  - Linear model is very simple, for this case, pay special attention to the **number of classes** and the **learning rate** tunning.\n",
        "  - Play with different configurations of **batch size**, it can have dramatic effects on how quick the model converges."
      ]
    },
    {
      "metadata": {
        "id": "jQBtZvi8CHKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "429ceddd-ac52-4ada-cb2f-3be5fedbfaee"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(    \n",
        "    feature_columns=my_feature_columns,\n",
        "    n_classes=3,\n",
        "    optimizer=tf.train.FtrlOptimizer(\n",
        "      learning_rate=0.1,\n",
        "      l1_regularization_strength=0.001\n",
        "    ))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpgveknbc4\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpgveknbc4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f4cec6a8a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L4U3QtsFDHpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "9ad1fa24-afe7-4631-c8f3-464f033da035"
      },
      "cell_type": "code",
      "source": [
        "classifier.train(input_fn=lambda: train_input_fn(X_train, y_train, batch_size=16), \n",
        "                 steps=1000 #  Number of steps for which to train model.\n",
        "                )"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpgveknbc4/model.ckpt.\n",
            "INFO:tensorflow:loss = 17.577797, step = 0\n",
            "INFO:tensorflow:global_step/sec: 241.053\n",
            "INFO:tensorflow:loss = 5.629356, step = 100 (0.418 sec)\n",
            "INFO:tensorflow:global_step/sec: 298.585\n",
            "INFO:tensorflow:loss = 6.692781, step = 200 (0.334 sec)\n",
            "INFO:tensorflow:global_step/sec: 279.367\n",
            "INFO:tensorflow:loss = 4.3902354, step = 300 (0.361 sec)\n",
            "INFO:tensorflow:global_step/sec: 250.665\n",
            "INFO:tensorflow:loss = 4.652293, step = 400 (0.396 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.653\n",
            "INFO:tensorflow:loss = 5.2302628, step = 500 (0.404 sec)\n",
            "INFO:tensorflow:global_step/sec: 245.815\n",
            "INFO:tensorflow:loss = 4.7758217, step = 600 (0.406 sec)\n",
            "INFO:tensorflow:global_step/sec: 257.672\n",
            "INFO:tensorflow:loss = 3.79697, step = 700 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 261.897\n",
            "INFO:tensorflow:loss = 3.7081466, step = 800 (0.383 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.421\n",
            "INFO:tensorflow:loss = 4.560728, step = 900 (0.396 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpgveknbc4/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 3.9127283.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f4cec6a8828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "metadata": {
        "id": "hA3DUaUIDtFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "8d5817b7-0c23-4129-bf0c-324a0e342121"
      },
      "cell_type": "code",
      "source": [
        "classifier.evaluate(input_fn=lambda: eval_input_fn(X_test, y_test, batch_size=512))"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-05-09-16:28:34\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpgveknbc4/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-05-09-16:28:35\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.26361477, global_step = 1000, loss = 7.9084435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.96666664,\n",
              " 'average_loss': 0.26361477,\n",
              " 'global_step': 1000,\n",
              " 'loss': 7.9084435}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "metadata": {
        "id": "sUO1b5G1HT6B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AuxmT16LtogI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Exercise**: Change the Linear Model Estimator to a Deep Neural Network.\n",
        "- Head over to the Tensorflow documentation for [tf.estimator.DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) and check it out.\n",
        "\n",
        "Think about how many layers you need, the number of units in each layer, the activation function used by default, and the Gradient Descent Optimizer. \n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/custom_estimators/full_network.png)"
      ]
    },
    {
      "metadata": {
        "id": "6C6iw34VuR2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}