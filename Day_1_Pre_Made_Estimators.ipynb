{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day_1_Pre_Made_Estimators.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/sthalles/tensorflow-tutorials/blob/master/Day_1_Pre_Made_Estimators.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "cqTmrQ_S2uHN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Pre-Made Estimators"
      ]
    },
    {
      "metadata": {
        "id": "Rs-U0Gbg2tOT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "5db1712b-8733-48d9-8d8e-8479437741c9"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "09FZfGX73c10",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The Estimator is a high-level Tensorflow API. \n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/tensorflow_programming_environment.png)\n",
        "\n",
        "It provides functionalities for representing a complete model.\n",
        "1. Building the actual model\n",
        "2. Initialization\n",
        "3. Logging\n",
        "3. Saving and restoring\n",
        "2. Measuring\n",
        "3. Testing\n",
        "\n",
        "To write a TensorFlow program based on pre-made Estimators, you must perform the following tasks:\n",
        "\n",
        "1.  Create one or more **input functions**.\n",
        "2.  Define the model's **feature columns**.\n",
        "3. Instantiate an Estimator, specifying the feature columns and various hyperparameters.\n",
        "4. Train and Evaluate\n",
        "\n",
        "# Loading data"
      ]
    },
    {
      "metadata": {
        "id": "zyFPmARd8fUg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "02adb682-dd95-4e9d-9217-e48753b507f6"
      },
      "cell_type": "code",
      "source": [
        "def maybe_download():\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GmASDzpA3zBn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "4464abc0-c62a-4d30-94b4-54005a8b7873"
      },
      "cell_type": "code",
      "source": [
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "  train_path, test_path = maybe_download()\n",
        "  train_data = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  test_data = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "  \n",
        "  train_input = train_data[CSV_COLUMN_NAMES[0:-1]]\n",
        "  train_labels = train_data[CSV_COLUMN_NAMES[-1]]\n",
        "  \n",
        "  test_input = test_data[CSV_COLUMN_NAMES[0:-1]]\n",
        "  test_labels = test_data[CSV_COLUMN_NAMES[-1]]\n",
        "  \n",
        "  return (train_input, train_labels), (test_input, test_labels)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_HNxFcVM8fyz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "634edce7-c7c1-4f7e-c88c-19584bd62a77"
      },
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = load_dataset()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
            "\r8192/2194 [================================================================================================================] - 0s 0us/step\n",
            "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
            "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XE0JRtOAJ1Qi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating Input funcions\n",
        "\n",
        "The Estimator expects an input_function() to return a [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) or a tuple of *(features, labels)*.\n",
        "\n",
        "Let's use the tf.data.Dataset as our input streaming.\n",
        "-  [tf.data.Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) is the recommended input pipeline."
      ]
    },
    {
      "metadata": {
        "id": "g69sCY5S8zYk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "656ddec5-24b7-4707-e880-d96d7f66ecce"
      },
      "cell_type": "code",
      "source": [
        "def train_input_fn(features, labels, batch_size):\n",
        "  \"\"\"\n",
        "  A function that provides input data for training as minibatches\n",
        "  Return: A 'tf.data.Dataset' object: tuple (features, labels). \n",
        "          Or tuple (features, labels)\n",
        "  \"\"\"\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "  dataset = dataset.shuffle(buffer_size=100)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3aWlJkPaGrXg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "74aa784e-ec12-4b3c-cc8e-c71e30ca2887"
      },
      "cell_type": "code",
      "source": [
        "def eval_input_fn(features, labels, batch_size):\n",
        "  \n",
        "  features = dict(features)\n",
        "  if labels is None:\n",
        "    inputs = features\n",
        "  else:\n",
        "    inputs = (dict(features), labels)\n",
        "  \n",
        "  dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "  dataset = dataset.repeat(1)\n",
        "  dataset = dataset.batch(batch_size)\n",
        "  return dataset"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pf6z_QJxEFFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining the Feature Columns\n",
        "\n",
        "Now, we have to convert our data into **Tensors** so that our Model can use it.\n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/feature_columns/some_constructors.jpg)\n",
        "\n",
        "**Feature Columns** define the **type of features** we are going to feed into our Models.\n",
        "\n",
        "Since the 4 feature columns of the Iris dataset are represented as continuos values, we need to especify it when creating the feature columns.\n",
        "\n",
        "To do that, we use the: [tf.feature_column.numeric_column()](https://www.tensorflow.org/api_docs/python/tf/feature_column/numeric_column) constructor.\n",
        "\n",
        "  - **tf.feature_column.numeric_column()** Represents real valued or numerical features.\n",
        "  \n",
        "Checkout: [Feature Engineering](https://www.tensorflow.org/get_started/feature_columns)\n",
        "  \n",
        " \n"
      ]
    },
    {
      "metadata": {
        "id": "PJEWtWQ_-v9s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2029d5f9-ac8c-4ded-e049-221e790cc832"
      },
      "cell_type": "code",
      "source": [
        "# feature columns define how to use the feature data\n",
        "my_feature_columns = []\n",
        "for feature_column in X_train.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=feature_column))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iihk9U-ubQbr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "1. Tune the hyperparameters bellow."
      ]
    },
    {
      "metadata": {
        "id": "QRwjJ4qbbbzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c738360d-4912-4d6f-b41e-56480a1133c2"
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "number_of_classes = 3\n",
        "batch_size = 16\n",
        "max_step = 1000\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wCQTOJnbCjFo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building the Estimator\n",
        "\n",
        "An Estimator encapsulates all the necessary parts of a model. \n",
        "\n",
        "Some of the available Estimators include:\n",
        "\n",
        "1. **BoostedTrees** Classifier/Regressor\n",
        "2. **DNN Classifier**/Regressor\n",
        "3. **DNNLinearCombined** Classifier/Regressor\n",
        "4. **Linear** Classifier/Regressor\n",
        "\n",
        "Checkout: [tf.estimator](https://www.tensorflow.org/api_docs/python/tf/estimator)\n",
        "\n",
        "## Exercise\n",
        "\n",
        "1. Use the **tf.estimator.LinearClassifier** to classify the Iris Dataset.\n",
        "\n",
        "Things to keep in mind.\n",
        "  - Linear models are very simple, for this case, pay special attention to the **number of classes** and the **learning rate** tunning.\n",
        "  - Play with different configurations of **batch size**, it can have dramatic effects on how quick the model converges."
      ]
    },
    {
      "metadata": {
        "id": "jQBtZvi8CHKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "a3f40b7a-6aa2-481f-d0e7-35434cb6397d"
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.LinearClassifier(    \n",
        "    feature_columns=my_feature_columns,\n",
        "    n_classes=number_of_classes,\n",
        "    optimizer=tf.train.FtrlOptimizer(\n",
        "      learning_rate=learning_rate,\n",
        "      l1_regularization_strength=0.001\n",
        "    ))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpk6ty2hho\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpk6ty2hho', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f39aca0ef28>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L4U3QtsFDHpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "883d356c-d87a-4228-c2e3-fd869e258c20"
      },
      "cell_type": "code",
      "source": [
        "classifier.train(input_fn=lambda: train_input_fn(X_train, y_train, batch_size=batch_size), \n",
        "                 steps=max_step #  Number of steps for which to train model.\n",
        "                )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpk6ty2hho/model.ckpt.\n",
            "INFO:tensorflow:loss = 17.577797, step = 0\n",
            "INFO:tensorflow:global_step/sec: 278.412\n",
            "INFO:tensorflow:loss = 6.420633, step = 100 (0.364 sec)\n",
            "INFO:tensorflow:global_step/sec: 301.772\n",
            "INFO:tensorflow:loss = 4.9447355, step = 200 (0.333 sec)\n",
            "INFO:tensorflow:global_step/sec: 302.855\n",
            "INFO:tensorflow:loss = 6.3400536, step = 300 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 255.452\n",
            "INFO:tensorflow:loss = 5.9765987, step = 400 (0.395 sec)\n",
            "INFO:tensorflow:global_step/sec: 251.835\n",
            "INFO:tensorflow:loss = 4.7573376, step = 500 (0.393 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.326\n",
            "INFO:tensorflow:loss = 5.26486, step = 600 (0.415 sec)\n",
            "INFO:tensorflow:global_step/sec: 252.541\n",
            "INFO:tensorflow:loss = 4.886089, step = 700 (0.390 sec)\n",
            "INFO:tensorflow:global_step/sec: 248.25\n",
            "INFO:tensorflow:loss = 4.7933187, step = 800 (0.408 sec)\n",
            "INFO:tensorflow:global_step/sec: 243.578\n",
            "INFO:tensorflow:loss = 3.4691482, step = 900 (0.406 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpk6ty2hho/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 3.651227.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f39aca0ecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "hA3DUaUIDtFY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "outputId": "7477a15b-ca2a-4be1-90ef-e3e072e6d9fa"
      },
      "cell_type": "code",
      "source": [
        "classifier.evaluate(input_fn=lambda: eval_input_fn(X_test, y_test, batch_size=512))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-05-14-16:16:07\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpk6ty2hho/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-05-14-16:16:07\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.93333334, average_loss = 0.26765403, global_step = 1000, loss = 8.029621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.93333334,\n",
              " 'average_loss': 0.26765403,\n",
              " 'global_step': 1000,\n",
              " 'loss': 8.029621}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "AuxmT16LtogI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Deep Neural Networks\n",
        "\n",
        "## Exercise\n",
        "\n",
        "1. Change the Linear Model Estimator to a Deep Neural Network.\n",
        "- Head over to the Tensorflow documentation for [tf.estimator.DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) and check it out.\n",
        "\n",
        "Think about how many layers you need, the number of units in each layer, the activation function used by default, and the Gradient Descent Optimizer. \n",
        "\n",
        "![alt text](https://www.tensorflow.org/images/custom_estimators/full_network.png)\n",
        "\n",
        "## Architecturing your network\n",
        "\n",
        "![LeNet-5](http://cs231n.github.io/assets/nn1/layer_sizes.jpeg)\n",
        "\n",
        "Neural Nets with more hidden layers are able to represent more complex functions. \n",
        "\n",
        "- With more power comes complicated decision boundaries.\n",
        "\n",
        "Take care with **Overfitting**!\n",
        "\n",
        "- It occurs when a model with **high capacity** fits the noise in the data instead of the (assumed) underlying relationship.\n"
      ]
    },
    {
      "metadata": {
        "id": "07xM_Mh0dlc8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Regularization\n",
        "\n",
        "Effects of Regularization. The figure bellow shows the decision boundaries of the same DNN (20 hidden units), with different regularization penalties. \n",
        "\n",
        "Note that more regularization smooths the decision boundary.\n",
        "\n",
        "- It fights **Overfitting**.\n",
        "\n",
        "![alt text](http://cs231n.github.io/assets/nn1/reg_strengths.jpeg)"
      ]
    },
    {
      "metadata": {
        "id": "6C6iw34VuR2Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}